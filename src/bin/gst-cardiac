#!/usr/bin/env python


#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


from optparse import OptionParser
import os
import sys


import pygtk
pygtk.require("2.0")
import gobject
gobject.threads_init()
import pygst
pygst.require("0.10")
import gst


from cardiacam import videotypes


__author__ = "Kipp Cannon <kcannon@cita.utoronto.ca>"
__version__ = "FIXME"
__date__ = "FIXME"


#
# =============================================================================
#
#                            Pipeline Construction
#
# =============================================================================
#


def mkelem(pipeline, src, elem_type_name, **properties):
	if "name" in properties:
		elem = gst.element_factory_make(elem_type_name, properties.pop("name"))
	else:
		elem = gst.element_factory_make(elem_type_name)
	for name, value in properties.items():
		elem.set_property(name.replace("_", "-"), value)
	pipeline.add(elem)
	if isinstance(src, gst.Pad):
		src.get_parent_element().link_pads(src, elem, None)
	elif src is not None:
		src.link(elem)
	return elem


def write_dump_dot(pipeline, filestem, verbose = False):
	"""
	This function needs the environment variable GST_DEBUG_DUMP_DOT_DIR
	to be set.   The filename will be

	os.path.join($GST_DEBUG_DUMP_DOT_DIR, filestem + ".dot")

	If verbose is True, a message will be written to stderr.
	"""
	if "GST_DEBUG_DUMP_DOT_DIR" not in os.environ:
		raise ValueError("cannot write pipeline, environment variable GST_DEBUG_DUMP_DOT_DIR is not set")
	gst.DEBUG_BIN_TO_DOT_FILE(pipeline, gst.DEBUG_GRAPH_SHOW_ALL, filestem)
	if verbose:
		print >>sys.stderr, "Wrote pipeline to %s" % os.path.join(os.environ["GST_DEBUG_DUMP_DOT_DIR"], "%s.dot" % filestem)


class src_deferred_link(object):
	def __init__(self, src, srcpadname, sinkpad):
		no_more_pads_handler_id = src.connect("no-more-pads", self.no_more_pads, srcpadname)
		src.connect("pad-added", self.pad_added, (srcpadname, sinkpad, no_more_pads_handler_id))

	@staticmethod
	def pad_added(element, pad, (srcpadname, sinkpad, no_more_pads_handler_id)):
		if pad.get_name() == srcpadname:
			pad.get_parent().handler_disconnect(no_more_pads_handler_id)
			pad.link(sinkpad)

	@staticmethod
	def no_more_pads(element, srcpadname):
		raise ValueError("<%s>: no pad named '%s'" % (element.get_name(), srcpadname))


#
# =============================================================================
#
#                                 Command Line
#
# =============================================================================
#


def parse_command_line():
	parser = OptionParser(
		version = "%prog ??",
		usage = "%prog [options] filename",
		description = "Extract cardiac pulse from a video of a patient."
	)
	parser.add_option("--no-display", action = "store_true", help = "Do not display video in window (allows code to run faster than realtime).")
	parser.add_option("--input", metavar = "filename", default = "/dev/video0", help = "Set the name of the input file (default = \"/dev/video0\").  If the filename starts with \"/dev/\" then it is assumed to be a V4L device.")

	options, filenames = parser.parse_args()

	return options, filenames


#
# =============================================================================
#
#                              Face Processor Bin
#
# =============================================================================
#


class face_processor(gst.Bin):
	"""
	Face processor bin.
	"""

	__gstdetails__ = (
		"Face Processor",
		"Filter",
		__doc__,
		__author__
	)

	__gproperties__ = {
		"face-x" : (
			gobject.TYPE_INT,
			"face-x",
			"left edge of face",
			0, gobject.G_MAXINT, 0,
			gobject.PARAM_READWRITE | gobject.PARAM_CONSTRUCT
		),
		"face-y" : (
			gobject.TYPE_INT,
			"face-y",
			"top of face",
			0, gobject.G_MAXINT, 0,
			gobject.PARAM_READWRITE | gobject.PARAM_CONSTRUCT
		),
		"face-width" : (
			gobject.TYPE_INT,
			"face-width",
			"width of face",
			0, gobject.G_MAXINT, 0,
			gobject.PARAM_READWRITE | gobject.PARAM_CONSTRUCT
		),
		"face-height" : (
			gobject.TYPE_INT,
			"face-height",
			"height of face",
			0, gobject.G_MAXINT, 0,
			gobject.PARAM_READWRITE | gobject.PARAM_CONSTRUCT
		)
	}

	def do_set_property(self, prop, val):
		if prop.name in ("face-x", "face-y", "face-width", "face-height"):
			self.face2rgb.set_property(prop.name, val)
		else:
			raise AssertionError

	def do_get_property(self, prop):
		if prop.name in ("face-x", "face-y", "face-width", "face-height"):
			return self.face2rgb.get_property(prop.name)
		else:
			raise AssertionError

	def __init__(self):
		#
		# initialize
		#

		super(face_processor, self).__init__()

		#
		# convert to RGB time series at video native frame rate
		#

		self.face2rgb = head = mkelem(self, None, "face2rgb", gamma = 2.2)
		self.add_pad(gst.GhostPad("sink", head.get_pad("sink")))

		#
		# resample to 48 Hz (integer sample rate = compatible with
		# all audio elements)
		#

		head = mkelem(self, mkelem(self, head, "audiorationalresample"), "capsfilter", caps = gst.Caps("audio/x-raw-float, rate=48"))

		#
		# band pass filter
		#

		head = mkelem(self, head, "audiochebband", lower_frequency = .5, upper_frequency = 5., poles = 4)

		#
		# dump to text file
		#

		mkelem(self, mkelem(self, mkelem(self, head, "queue"), "lal_nxydump"), "fdsink", fd = 1, sync = False, async = False)


gobject.type_register(face_processor)
gst.element_register(face_processor, face_processor.__name__)


#
# =============================================================================
#
#                                   Pipeline
#
# =============================================================================
#


class Handler(object):
	def __init__(self, mainloop, pipeline):
		self.mainloop = mainloop
		self.pipeline = pipeline

		self.src = None
		self.face_processors = []

		bus = pipeline.get_bus()
		bus.add_signal_watch()
		bus.connect("message", self.on_message)

	def on_message(self, bus, message):
		if message.type == gst.MESSAGE_ELEMENT:
			s = message.structure
			if s.get_name() == "facedetect":
				self.do_facedetect_message(message.src, s)
		elif message.type == gst.MESSAGE_EOS:
			self.pipeline.set_state(gst.STATE_NULL)
			self.mainloop.quit()
		elif message.type == gst.MESSAGE_ERROR:
			gerr, dbgmsg = message.parse_error()
			print >>sys.stderr, "error (%s:%d '%s'): %s" % (gerr.domain, gerr.code, gerr.message, dbgmsg)
			sys.exit(1)

	def do_facedetect_message(self, elem, s):
		#
		# s is a GstStructure w/ elements:
		#
		#   timestamp:  uint64
		#   duration:  uint64
		#	timestamp and duration of current video buffer
		#   stream-time:  uint64
		#   running-time:  uint64
		#	of location in stream
		#   faces:  list
		#	containing structures with name "face" and elements:
		#	   x
		#	   y
		#	   width
		#	   height
		#		top-left corner and extent of face
		#	   nose->x
		#	   nose->y
		#	   nose->width
		#	   nose->height
		#		top-left corner and extent of nose
		#	   mouth->x
		#	   mouth->y
		#	   mouth->width
		#	   mouth->height
		#		top-left corner and extent of mouth
		#	   eyes->x
		#	   eyes->y
		#	   eyes->width
		#	   eyes->height
		#		top-left corner and extent of eyes
		#

		faces = s["faces"]

		#
		# do we need to add face processors?
		#

		if len(faces) > len(self.face_processors):
			self.pipeline.set_state(gst.STATE_PAUSED)
			while len(faces) > len(self.face_processors) and self.src is not None:
				queue = mkelem(self.pipeline, None, "queue", max_size_time = gst.SECOND)
				queue.set_state(gst.STATE_PAUSED)
				self.face_processors.append(mkelem(self.pipeline, queue, "face_processor"))
				self.face_processors[-1].set_state(gst.STATE_PAUSED)
				self.src.link(queue)
			self.pipeline.set_state(gst.STATE_PLAYING)
			#write_dump_dot(self.pipeline, "blah", verbose = True)

		#
		# do we need to remove any?
		#

		if len(faces) < len(self.face_processors):
			pass
			#for face_processor in self.face_processors[len(faces):]:
			#	self.pipeline.remove(face_processor)

		#
		# update face locations
		#

		for face_processor, face in zip(self.face_processors, faces):
			face_processor.set_property("face-x", face["x"])
			face_processor.set_property("face-y", face["y"])
			face_processor.set_property("face-width", face["width"])
			face_processor.set_property("face-height", face["height"])


options, filenames = parse_command_line()


pipeline = gst.Pipeline("pipeline")
mainloop = gobject.MainLoop()
handler = Handler(mainloop, pipeline)


if options.input.startswith("/dev/"):
	src = mkelem(pipeline, mkelem(pipeline, None, "v4l2src", device = options.input), "ffmpegcolorspace")
else:
	src = mkelem(pipeline, mkelem(pipeline, None, "filesrc", location = options.input), "decodebin2")
	elem = mkelem(pipeline, None, "ffmpegcolorspace")
	src_deferred_link(src, "src0", elem.get_pad("sink"))
	src = elem

handler.src = src = mkelem(pipeline, mkelem(pipeline, src, "capsfilter", caps = gst.Caps(videotypes.video_caps)), "tee")

def facedetect_sink_caps_hander(pad, pspec, ignored):
	caps = pad.get_property("caps")
	if caps is not None:
		elem = pad.get_parent()
		s = caps[0]
		elem.set_property("min-size-width", s["width"] // 6)
		elem.set_property("min-size-height", s["height"] // 4)
src = mkelem(pipeline, src, "facedetect", scale_factor = 1.1)
src.get_pad("sink").connect("notify::caps", facedetect_sink_caps_hander, None)

if not options.no_display:
	src = mkelem(pipeline, src, "queue", max_size_buffers = 0, max_size_time = 0, max_size_bytes = 0)
	mkelem(pipeline, mkelem(pipeline, src, "ffmpegcolorspace"), "autovideosink")
else:
	mkelem(pipeline, src, "fakesink", sync = False, async = False)

pipeline.set_state(gst.STATE_PLAYING)
mainloop.run()

